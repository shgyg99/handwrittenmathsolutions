{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shgyg99/handwrittenmathsolutions/blob/main/mathTOlatex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hi7OmzqQj_Te"
      },
      "source": [
        "# **ðŸ”´ENVIRONMENT SETUP**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "G2TVFhIEk7ib"
      },
      "outputs": [],
      "source": [
        "!pip install -q torchmetrics\n",
        "!pip install -q wandb\n",
        "!pip install -q fastai\n",
        "!pip install -q pytorch_lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "A2MLu6bOFY6y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ec113c5-7e10-4360-8c5f-301c0e0e52e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torchvision 0.20.0\n",
            "Uninstalling torchvision-0.20.0:\n",
            "  Successfully uninstalled torchvision-0.20.0\n",
            "Found existing installation: torch 2.5.0\n",
            "Uninstalling torch-2.5.0:\n",
            "  Successfully uninstalled torch-2.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip uninstall torchvision torch -y\n",
        "!pip install -q torch==2.5 torchvision==0.20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFEbeoVYlLRg"
      },
      "source": [
        "# **ðŸ”´IMPORT LIBS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LWODQ4BLjblB"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import os\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms as TT\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torch import optim\n",
        "from torch.nn import functional as F\n",
        "\n",
        "from tokenizers import Tokenizer, models, trainers, pre_tokenizers\n",
        "import wandb\n",
        "import tqdm\n",
        "import torchmetrics as tm\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5bNJaBDlhbl"
      },
      "source": [
        "# **ðŸ”´UTILS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HeLrwBOvlg5j"
      },
      "outputs": [],
      "source": [
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mj2ouMgDlmnr"
      },
      "outputs": [],
      "source": [
        "def num_trainable_params(model):\n",
        "  nums = sum(p.numel() for p in model.parameters() if p.requires_grad)/1e6\n",
        "  return nums"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nQZtnlwflobp"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed):\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  if torch.cuda.is_available():\n",
        "      torch.cuda.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZJ2on11ltK-"
      },
      "source": [
        "# **ðŸ”´ARGUMENTS**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    \"seed\": 1234,\n",
        "\n",
        "    \"trainer\": {\n",
        "        \"overfit_batches\": 0.0,\n",
        "        \"check_val_every_n_epoch\": 2,\n",
        "        \"fast_dev_run\": False,\n",
        "        \"max_epochs\": 15,\n",
        "        \"min_epochs\": 1,\n",
        "        \"num_sanity_val_steps\": 0,\n",
        "    },\n",
        "\n",
        "    \"callbacks\": {\n",
        "        \"model_checkpoint\": {\n",
        "            \"save_top_k\": 1,\n",
        "            \"save_weights_only\": True,\n",
        "            \"mode\": \"min\",\n",
        "            \"monitor\": \"val/loss\",\n",
        "            \"filename\": \"{epoch}-{val/loss:.2f}-{val/cer:.2f}\"\n",
        "        },\n",
        "        \"early_stopping\": {\n",
        "            \"patience\": 3,\n",
        "            \"mode\": \"min\",\n",
        "            \"monitor\": \"val/loss\",\n",
        "            \"min_delta\": 0.001\n",
        "        }\n",
        "    },\n",
        "\n",
        "    \"data\": {\n",
        "        \"batch_size\": 8,\n",
        "        \"num_workers\": 0,\n",
        "        \"pin_memory\": False\n",
        "    },\n",
        "\n",
        "    \"lit_model\": {\n",
        "        # Optimizer\n",
        "        \"lr\": 0.001,\n",
        "        \"weight_decay\": 0.0001,\n",
        "\n",
        "        # Scheduler\n",
        "        \"milestones\": [10],\n",
        "        \"gamma\": 0.5,\n",
        "\n",
        "        # Model\n",
        "        \"d_model\": 128,\n",
        "        \"dim_feedforward\": 256,\n",
        "        \"nhead\": 4,\n",
        "        \"dropout\": 0.3,\n",
        "        \"num_decoder_layers\": 3,\n",
        "        \"max_output_len\": 150\n",
        "    },\n",
        "\n",
        "    \"logger\": {\n",
        "        \"project\": \"image-to-latex\"\n",
        "    }\n",
        "}\n"
      ],
      "metadata": {
        "id": "MmNE3wyWx4dw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VqCs08IPlqLg"
      },
      "outputs": [],
      "source": [
        "seed = 8\n",
        "path = '/content/drive/MyDrive/papersFolder'\n",
        "embed_size=256\n",
        "hidden_size=512\n",
        "num_layers = 2\n",
        "dropout_embd = 0.5\n",
        "dropout_rnn = 0.5\n",
        "batch_size=16\n",
        "momentum=0.9\n",
        "num_epoch = 10\n",
        "wandb_enable = True\n",
        "seq_len = 20\n",
        "lr=0.001\n",
        "weight_decay=0.0001\n",
        "# Scheduler\n",
        "milestones=[10]\n",
        "gamma= 0.5\n",
        "# Model\n",
        "d_model= 128\n",
        "dim_feedforward=256\n",
        "nhead=4\n",
        "dropout=0.3\n",
        "num_decoder_layers=3\n",
        "max_output_len=150"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_WJRepJQcuB"
      },
      "source": [
        "# **ðŸ”´CUSTOM DATASET**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokens = [\n",
        "#     '\\\\', '{', '}', '^', '+', '-', \"'\", '_', '!', '.', '/', '&', '%', '*',\n",
        "#     '\\\\frac', '\\\\times', '\\\\lim', '\\\\sin', '\\\\cos', '\\\\tan', '\\\\cot', '\\\\csc', '\\\\sec',\n",
        "#     '\\\\sqrt', '\\\\sum', '\\\\rightarrow', '\\\\Rightarrow', '\\\\leftarrow', '\\\\Leftarrow',\n",
        "#     '\\\\right', '\\\\left', '\\\\alpha', '\\\\beta', '|', '\\\\Delta', '\\\\delta', '\\\\gamma', '\\\\lambda',\n",
        "#     '\\\\min', '\\\\max', '(', ')', '<', '>', '=', '\\\\pm', '\\\\mp', '\\\\neq', '\\\\infty', '\\\\matrix',\n",
        "#     '[', ']', '\\\\in', '\\\\notin', '\\\\cap', '\\\\cup', '\\\\begin', '\\\\end', '\\\\dots', '\\\\int', ':',\n",
        "#     '\\\\ln', '\\\\pi', '\\\\theta', '\\\\to', '\\\\arctan', '\\\\arccot', '\\\\arcsin', '\\\\arccos',\n",
        "#     '\\\\log', '\\\\sinh', '\\\\cosh', '\\\\coth', '\\\\tanh', '\\\\degree', '\\\\dev', '\\\\sim',\n",
        "#     '\\\\forall', '\\\\emptyset', '\\\\buildrelF', '\\\\bar', '\\\\exists', '\\\\varepsilon', '\\\\partial',\n",
        "#     '\\\\hat', '\\\\triangle', '\\\\mathbb', '\\\\simeq',\n",
        "#     'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z',\n",
        "#     'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
        "#     '0', '1', '2', '3', '4', '5', '6', '7', '8', '9'\n",
        "# ]\n",
        "\n",
        "# tokenizer = Tokenizer(models.BPE())\n",
        "\n",
        "# special_tokens = [\"<s>\", \"</s>\", \"<unk>\", \"<pad>\"] + tokens\n",
        "# trainer = trainers.BpeTrainer(vocab_size=len(special_tokens), special_tokens=special_tokens)\n",
        "\n",
        "# tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n",
        "\n",
        "# files = [\"/content/drive/MyDrive/papersFolder/latex_formulas.txt\"]\n",
        "# tokenizer.train(files, trainer)\n",
        "\n",
        "# # Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„\n",
        "# tokenizer.save(\"/content/drive/MyDrive/papersFolder/latex_tokenizer.json\")\n",
        "\n",
        "# print(\"âœ…Done\")"
      ],
      "metadata": {
        "id": "JUjWVndOluvJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def target_transform(label):\n",
        "  tokenizer = Tokenizer.from_file(f\"{path}/latex_tokenizer.json\")\n",
        "  encoded_label = tokenizer.encode(f'<s>{label}</s>')\n",
        "  return torch.LongTensor(encoded_label.ids)"
      ],
      "metadata": {
        "id": "zvHArRPuhwts"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_transform = TT.Compose([\n",
        "    TT.Grayscale(num_output_channels=1),\n",
        "    TT.Resize((256, 512)),\n",
        "    TT.ToTensor(),\n",
        "    TT.Normalize(mean=[0.5], std=[0.5])\n",
        "])"
      ],
      "metadata": {
        "id": "AxHJ3t4kiyCG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "bi1fMdFOQE-6"
      },
      "outputs": [],
      "source": [
        "class LatexImages(Dataset):\n",
        "  def __init__(self, path, image_transform=None, target_transform=None):\n",
        "    self.path = path\n",
        "    self.image_transform = image_transform\n",
        "    self.target_transform = target_transform\n",
        "\n",
        "    csv = pd.read_csv(os.path.join(self.path, 'merged_sorted.csv'))\n",
        "\n",
        "    self.image_paths = []\n",
        "    self.labels = []\n",
        "    for i in os.listdir(os.path.join(self.path, 'cropped')):\n",
        "        image_path = fr'.\\cropped\\{i}'\n",
        "        try:\n",
        "          label = csv[csv['Image Path'] == image_path]['LaTeX Label'].values[0]\n",
        "          self.image_paths.append(os.path.join(self.path, 'cropped', i))\n",
        "          self.labels.append(label)\n",
        "        except:\n",
        "          pass\n",
        "\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    image_path = self.image_paths[index]\n",
        "\n",
        "    if self.target_transform:\n",
        "      label = self.target_transform(self.labels[index])\n",
        "    else:\n",
        "      label = self.labels[index]\n",
        "\n",
        "    if self.image_transform:\n",
        "      image = self.image_transform(Image.open(image_path))\n",
        "    else:\n",
        "      image = Image.open(image_path)\n",
        "\n",
        "    return image, label\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.image_paths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "AHi-cTp4UIgd"
      },
      "outputs": [],
      "source": [
        "dataset = LatexImages(path=path, image_transform=image_transform, target_transform=target_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "FsZ45t_EbGLe",
        "outputId": "5b89406c-be98-4742-9017-43de6edad3a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 256, 512]) torch.Size([17])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "im, la = dataset.__getitem__(np.random.randint(0, dataset.__len__()))\n",
        "\n",
        "plt.imshow(TT.ToPILImage()(im))\n",
        "print(im.shape, la.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ðŸ”´Data Loader**"
      ],
      "metadata": {
        "id": "Tq2Ryx5Dk8km"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set, test_set = random_split(dataset, [int(len(dataset)*0.9), len(dataset)-int(len(dataset)*0.9)])"
      ],
      "metadata": {
        "id": "1svWDEsXmkse"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(data):\n",
        "    tokenizer = Tokenizer.from_file(f\"{path}/latex_tokenizer.json\")\n",
        "    pad_value = tokenizer.get_vocab().get('<pad>', 3)\n",
        "    tensors, targets = zip(*data)\n",
        "    targets = [torch.tensor(t, dtype=torch.long) for t in targets]\n",
        "    features = pad_sequence(targets, padding_value=pad_value, batch_first=True)\n",
        "    try:\n",
        "        tensors = torch.stack(tensors)\n",
        "    except RuntimeError as e:\n",
        "        print(f\"stack error: {e}\")\n",
        "        for i, t in enumerate(tensors):\n",
        "            print(f\"tensor shape error {i}: {t.shape}\")\n",
        "\n",
        "    return tensors, features"
      ],
      "metadata": {
        "id": "QALwTzOJgyE4"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, pin_memory=True, num_workers=4)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, pin_memory=True)"
      ],
      "metadata": {
        "id": "ces-ckAimjmH"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = next(iter(train_loader))\n",
        "x.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggBhGWhYnnBD",
        "outputId": "652ba3e8-c32a-4b12-83b2-5b0d4ee6fb38"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([16, 1, 256, 512]), torch.Size([16, 54]))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ðŸ”´Metric**"
      ],
      "metadata": {
        "id": "0Pifowx-rjej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "YMd_SbG0syuX",
        "outputId": "af18bc06-f86e-4fb8-e27b-97348a9d7e69"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import editdistance\n",
        "from typing import Set\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torchmetrics import Metric\n",
        "\n",
        "\n",
        "class CharacterErrorRate(Metric):\n",
        "    def __init__(self, ignore_indices: Set[int], *args):\n",
        "        super().__init__(*args)\n",
        "        self.ignore_indices = ignore_indices\n",
        "        self.add_state(\"error\", default=torch.tensor(0.0), dist_reduce_fx=\"sum\")\n",
        "        self.add_state(\"total\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
        "        self.error: Tensor\n",
        "        self.total: Tensor\n",
        "\n",
        "    def update(self, preds, targets):\n",
        "        N = preds.shape[0]\n",
        "        for i in range(N):\n",
        "            pred = [token for token in preds[i].tolist() if token not in self.ignore_indices]\n",
        "            target = [token for token in targets[i].tolist() if token not in self.ignore_indices]\n",
        "            distance = editdistance.distance(pred, target)\n",
        "            if max(len(pred), len(target)) > 0:\n",
        "                self.error += distance / max(len(pred), len(target))\n",
        "        self.total += N\n",
        "\n",
        "    def compute(self) -> Tensor:\n",
        "        return self.error / self.total"
      ],
      "metadata": {
        "id": "OgRow6K_rpFO"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ðŸ”´Functions**"
      ],
      "metadata": {
        "id": "7WDNaXpjnB3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from typing import List\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from pytorch_lightning import LightningModule\n",
        "\n",
        "\n",
        "class LitResNetTransformer(LightningModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        d_model: int,\n",
        "        dim_feedforward: int,\n",
        "        nhead: int,\n",
        "        dropout: float,\n",
        "        num_decoder_layers: int,\n",
        "        max_output_len: int,\n",
        "        lr: float = 0.001,\n",
        "        weight_decay: float = 0.0001,\n",
        "        milestones: List[int] = [5],\n",
        "        gamma: float = 0.1,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.lr = lr\n",
        "        self.weight_decay = weight_decay\n",
        "        self.milestones = milestones\n",
        "        self.gamma = gamma\n",
        "\n",
        "        self.tokenizer = Tokenizer.from_file(f\"{path}/latex_tokenizer.json\")\n",
        "        self.model = ResNetTransformer(\n",
        "            d_model=d_model,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            nhead=nhead,\n",
        "            dropout=dropout,\n",
        "            num_decoder_layers=num_decoder_layers,\n",
        "            max_output_len=max_output_len,\n",
        "            sos_index=self.tokenizer.get_vocab()['<s>'],\n",
        "            eos_index=self.tokenizer.get_vocab()['</s>'],\n",
        "            pad_index=self.tokenizer.get_vocab()['<pad>'],\n",
        "            num_classes=tokenizer.get_vocab_size(),\n",
        "        )\n",
        "        self.loss_fn = nn.CrossEntropyLoss(ignore_index=self.tokenizer.get_vocab()['<pad>'])\n",
        "        self.val_cer = CharacterErrorRate({self.tokenizer.get_vocab()['<pad>'], self.tokenizer.get_vocab()['<s>'], self.tokenizer.get_vocab()['</s>']})\n",
        "        self.test_cer = CharacterErrorRate({self.tokenizer.get_vocab()['<pad>'], self.tokenizer.get_vocab()['<s>'], self.tokenizer.get_vocab()['</s>']})\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        imgs, targets = batch\n",
        "        logits = self.model(imgs, targets[:, :-1])\n",
        "        loss = self.loss_fn(logits, targets[:, 1:])\n",
        "        self.log(\"train/loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        imgs, targets = batch\n",
        "        logits = self.model(imgs, targets[:, :-1])\n",
        "        loss = self.loss_fn(logits, targets[:, 1:])\n",
        "        self.log(\"val/loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
        "\n",
        "        preds = self.model.predict(imgs)\n",
        "        val_cer = self.val_cer(preds, targets)\n",
        "        self.log(\"val/cer\", val_cer)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        imgs, targets = batch\n",
        "        preds = self.model.predict(imgs)\n",
        "        test_cer = self.test_cer(preds, targets)\n",
        "        self.log(\"test/cer\", test_cer)\n",
        "        return preds\n",
        "\n",
        "    def test_epoch_end(self, test_outputs):\n",
        "        with open(f\"{path}/test_predictions.txt\", \"w\") as f:\n",
        "            for preds in test_outputs:\n",
        "                for pred in preds:\n",
        "                    decoded = self.tokenizer.decode(pred.tolist())\n",
        "                    decoded.append(\"\\n\")\n",
        "                    decoded_str = \" \".join(decoded)\n",
        "                    f.write(decoded_str)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
        "        scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=self.milestones, gamma=self.gamma)\n",
        "        return [optimizer], [scheduler]"
      ],
      "metadata": {
        "id": "fl-5ILMmra1a"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ðŸ”´Model**"
      ],
      "metadata": {
        "id": "qQrcAWNgnVt5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import Tensor\n",
        "\n",
        "\n",
        "class PositionalEncoding2D(nn.Module):\n",
        "    \"\"\"2-D positional encodings for the feature maps produced by the encoder.\n",
        "\n",
        "    Following https://arxiv.org/abs/2103.06450 by Sumeet Singh.\n",
        "\n",
        "    Reference:\n",
        "    https://github.com/full-stack-deep-learning/fsdl-text-recognizer-2021-labs/blob/main/lab9/text_recognizer/models/transformer_util.py\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_model: int, max_h: int = 2000, max_w: int = 2000) -> None:\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        assert d_model % 2 == 0, f\"Embedding depth {d_model} is not even\"\n",
        "        pe = self.make_pe(d_model, max_h, max_w)  # (d_model, max_h, max_w)\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    @staticmethod\n",
        "    def make_pe(d_model: int, max_h: int, max_w: int) -> Tensor:\n",
        "        \"\"\"Compute positional encoding.\"\"\"\n",
        "        pe_h = PositionalEncoding1D.make_pe(d_model=d_model // 2, max_len=max_h)  # (max_h, 1 d_model // 2)\n",
        "        pe_h = pe_h.permute(2, 0, 1).expand(-1, -1, max_w)  # (d_model // 2, max_h, max_w)\n",
        "\n",
        "        pe_w = PositionalEncoding1D.make_pe(d_model=d_model // 2, max_len=max_w)  # (max_w, 1, d_model // 2)\n",
        "        pe_w = pe_w.permute(2, 1, 0).expand(-1, max_h, -1)  # (d_model // 2, max_h, max_w)\n",
        "\n",
        "        pe = torch.cat([pe_h, pe_w], dim=0)  # (d_model, max_h, max_w)\n",
        "        return pe\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"Forward pass.\n",
        "\n",
        "        Args:\n",
        "            x: (B, d_model, H, W)\n",
        "\n",
        "        Returns:\n",
        "            (B, d_model, H, W)\n",
        "        \"\"\"\n",
        "        assert x.shape[1] == self.pe.shape[0]  # type: ignore\n",
        "        x = x + self.pe[:, : x.size(2), : x.size(3)]  # type: ignore\n",
        "        return x\n",
        "\n",
        "\n",
        "class PositionalEncoding1D(nn.Module):\n",
        "    \"\"\"Classic Attention-is-all-you-need positional encoding.\"\"\"\n",
        "\n",
        "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000) -> None:\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        pe = self.make_pe(d_model, max_len)  # (max_len, 1, d_model)\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    @staticmethod\n",
        "    def make_pe(d_model: int, max_len: int) -> Tensor:\n",
        "        \"\"\"Compute positional encoding.\"\"\"\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(1)\n",
        "        return pe\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"Forward pass.\n",
        "\n",
        "        Args:\n",
        "            x: (S, B, d_model)\n",
        "\n",
        "        Returns:\n",
        "            (B, d_model, H, W)\n",
        "        \"\"\"\n",
        "        assert x.shape[2] == self.pe.shape[2]  # type: ignore\n",
        "        x = x + self.pe[: x.size(0)]  # type: ignore\n",
        "        return self.dropout(x)"
      ],
      "metadata": {
        "id": "QhxtHgqFowZ6"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Union\n",
        "\n",
        "class ResNetTransformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        d_model: int,\n",
        "        dim_feedforward: int,\n",
        "        nhead: int,\n",
        "        dropout: float,\n",
        "        num_decoder_layers: int,\n",
        "        max_output_len: int,\n",
        "        sos_index: int,\n",
        "        eos_index: int,\n",
        "        pad_index: int,\n",
        "        num_classes: int,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.max_output_len = max_output_len + 2\n",
        "        self.sos_index = sos_index\n",
        "        self.eos_index = eos_index\n",
        "        self.pad_index = pad_index\n",
        "\n",
        "        # Encoder\n",
        "        resnet = torchvision.models.resnet18(pretrained=False)\n",
        "        self.backbone = nn.Sequential(\n",
        "            resnet.conv1,\n",
        "            resnet.bn1,\n",
        "            resnet.relu,\n",
        "            resnet.maxpool,\n",
        "            resnet.layer1,\n",
        "            resnet.layer2,\n",
        "            resnet.layer3,\n",
        "        )\n",
        "        self.bottleneck = nn.Conv2d(256, self.d_model, 1)\n",
        "        self.image_positional_encoder = PositionalEncoding2D(self.d_model)\n",
        "\n",
        "        # Decoder\n",
        "        self.embedding = nn.Embedding(num_classes, self.d_model)\n",
        "        self.y_mask = generate_square_subsequent_mask(self.max_output_len)\n",
        "        self.word_positional_encoder = PositionalEncoding1D(self.d_model, max_len=self.max_output_len)\n",
        "        transformer_decoder_layer = nn.TransformerDecoderLayer(self.d_model, nhead, dim_feedforward, dropout)\n",
        "        self.transformer_decoder = nn.TransformerDecoder(transformer_decoder_layer, num_decoder_layers)\n",
        "        self.fc = nn.Linear(self.d_model, num_classes)\n",
        "\n",
        "        # It is empirically important to initialize weights properly\n",
        "        if self.training:\n",
        "            self._init_weights()\n",
        "\n",
        "    def _init_weights(self) -> None:\n",
        "        \"\"\"Initialize weights.\"\"\"\n",
        "        init_range = 0.1\n",
        "        self.embedding.weight.data.uniform_(-init_range, init_range)\n",
        "        self.fc.bias.data.zero_()\n",
        "        self.fc.weight.data.uniform_(-init_range, init_range)\n",
        "\n",
        "        nn.init.kaiming_normal_(\n",
        "            self.bottleneck.weight.data,\n",
        "            a=0,\n",
        "            mode=\"fan_out\",\n",
        "            nonlinearity=\"relu\",\n",
        "        )\n",
        "        if self.bottleneck.bias is not None:\n",
        "            _, fan_out = nn.init._calculate_fan_in_and_fan_out(self.bottleneck.weight.data)\n",
        "            bound = 1 / math.sqrt(fan_out)\n",
        "            nn.init.normal_(self.bottleneck.bias, -bound, bound)\n",
        "\n",
        "    def forward(self, x: Tensor, y: Tensor) -> Tensor:\n",
        "        \"\"\"Forward pass.\n",
        "\n",
        "        Args:\n",
        "            x: (B, _E, _H, _W)\n",
        "            y: (B, Sy) with elements in (0, num_classes - 1)\n",
        "\n",
        "        Returns:\n",
        "            (B, num_classes, Sy) logits\n",
        "        \"\"\"\n",
        "        encoded_x = self.encode(x)  # (Sx, B, E)\n",
        "        output = self.decode(y, encoded_x)  # (Sy, B, num_classes)\n",
        "        output = output.permute(1, 2, 0)  # (B, num_classes, Sy)\n",
        "        return output\n",
        "\n",
        "    def encode(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"Encode inputs.\n",
        "\n",
        "        Args:\n",
        "            x: (B, C, _H, _W)\n",
        "\n",
        "        Returns:\n",
        "            (Sx, B, E)\n",
        "        \"\"\"\n",
        "        # Resnet expects 3 channels but training images are in gray scale\n",
        "        if x.shape[1] == 1:\n",
        "            x = x.repeat(1, 3, 1, 1)\n",
        "        x = self.backbone(x)  # (B, RESNET_DIM, H, W); H = _H // 32, W = _W // 32\n",
        "        x = self.bottleneck(x)  # (B, E, H, W)\n",
        "        x = self.image_positional_encoder(x)  # (B, E, H, W)\n",
        "        x = x.flatten(start_dim=2)  # (B, E, H * W)\n",
        "        x = x.permute(2, 0, 1)  # (Sx, B, E); Sx = H * W\n",
        "        return x\n",
        "\n",
        "    def decode(self, y: Tensor, encoded_x: Tensor) -> Tensor:\n",
        "        \"\"\"Decode encoded inputs with teacher-forcing.\n",
        "\n",
        "        Args:\n",
        "            encoded_x: (Sx, B, E)\n",
        "            y: (B, Sy) with elements in (0, num_classes - 1)\n",
        "\n",
        "        Returns:\n",
        "            (Sy, B, num_classes) logits\n",
        "        \"\"\"\n",
        "        y = y.permute(1, 0)  # (Sy, B)\n",
        "        y = self.embedding(y) * math.sqrt(self.d_model)  # (Sy, B, E)\n",
        "        y = self.word_positional_encoder(y)  # (Sy, B, E)\n",
        "        Sy = y.shape[0]\n",
        "        y_mask = self.y_mask[:Sy, :Sy].type_as(encoded_x)  # (Sy, Sy)\n",
        "        output = self.transformer_decoder(y, encoded_x, y_mask)  # (Sy, B, E)\n",
        "        output = self.fc(output)  # (Sy, B, num_classes)\n",
        "        return output\n",
        "\n",
        "    def predict(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"Make predctions at inference time.\n",
        "\n",
        "        Args:\n",
        "            x: (B, C, H, W). Input images.\n",
        "\n",
        "        Returns:\n",
        "            (B, max_output_len) with elements in (0, num_classes - 1).\n",
        "        \"\"\"\n",
        "        B = x.shape[0]\n",
        "        S = self.max_output_len\n",
        "\n",
        "        encoded_x = self.encode(x)  # (Sx, B, E)\n",
        "\n",
        "        output_indices = torch.full((B, S), self.pad_index).type_as(x).long()\n",
        "        output_indices[:, 0] = self.sos_index\n",
        "        has_ended = torch.full((B,), False)\n",
        "\n",
        "        for Sy in range(1, S):\n",
        "            y = output_indices[:, :Sy]  # (B, Sy)\n",
        "            logits = self.decode(y, encoded_x)  # (Sy, B, num_classes)\n",
        "            # Select the token with the highest conditional probability\n",
        "            output = torch.argmax(logits, dim=-1)  # (Sy, B)\n",
        "            output_indices[:, Sy] = output[-1:]  # Set the last output token\n",
        "\n",
        "            # Early stopping of prediction loop to speed up prediction\n",
        "            has_ended |= (output_indices[:, Sy] == self.eos_index).type_as(has_ended)\n",
        "            if torch.all(has_ended):\n",
        "                break\n",
        "\n",
        "        # Set all tokens after end token to be padding\n",
        "        eos_positions = find_first(output_indices, self.eos_index)\n",
        "        for i in range(B):\n",
        "            j = int(eos_positions[i].item()) + 1\n",
        "            output_indices[i, j:] = self.pad_index\n",
        "\n",
        "        return output_indices\n",
        "\n",
        "\n",
        "def generate_square_subsequent_mask(size: int) -> Tensor:\n",
        "    \"\"\"Generate a triangular (size, size) mask.\"\"\"\n",
        "    mask = (torch.triu(torch.ones(size, size)) == 1).transpose(0, 1)\n",
        "    mask = mask.float().masked_fill(mask == 0, float(\"-inf\")).masked_fill(mask == 1, float(0.0))\n",
        "    return mask\n",
        "\n",
        "\n",
        "def find_first(x: Tensor, element: Union[int, float], dim: int = 1) -> Tensor:\n",
        "    \"\"\"Find the first occurence of element in x along a given dimension.\n",
        "\n",
        "    Args:\n",
        "        x: The input tensor to be searched.\n",
        "        element: The number to look for.\n",
        "        dim: The dimension to reduce.\n",
        "\n",
        "    Returns:\n",
        "        Indices of the first occurence of the element in x. If not found, return the\n",
        "        length of x along dim.\n",
        "\n",
        "    Usage:\n",
        "        >>> first_element(Tensor([[1, 2, 3], [2, 3, 3], [1, 1, 1]]), 3)\n",
        "        tensor([2, 1, 3])\n",
        "\n",
        "    Reference:\n",
        "        https://discuss.pytorch.org/t/first-nonzero-index/24769/9\n",
        "\n",
        "        I fixed an edge case where the element we are looking for is at index 0. The\n",
        "        original algorithm will return the length of x instead of 0.\n",
        "    \"\"\"\n",
        "    mask = x == element\n",
        "    found, indices = ((mask.cumsum(dim) == 1) & mask).max(dim)\n",
        "    indices[(~found) & (indices == 0)] = x.shape[dim]\n",
        "    return indices"
      ],
      "metadata": {
        "id": "M2x0z6CfndBp"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ðŸ”´Test**"
      ],
      "metadata": {
        "id": "p1Bc6eSSvPTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from argparse import Namespace\n",
        "from typing import List, Optional\n",
        "\n",
        "# import hydra\n",
        "# from omegaconf import DictConfig\n",
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
        "from pytorch_lightning.loggers.wandb import WandbLogger\n",
        "\n",
        "lit_model = LitResNetTransformer(**config['lit_model']).to(device)\n",
        "\n",
        "callbacks: List[Callback] = []\n",
        "callbacks.append(ModelCheckpoint(**config['callbacks']['model_checkpoint']))\n",
        "callbacks.append(EarlyStopping(**config['callbacks']['early_stopping']))\n",
        "\n",
        "logger: Optional[WandbLogger] = None\n",
        "if config['logger']:\n",
        "  logger = WandbLogger(**config['logger'])\n",
        "\n",
        "trainer = Trainer(**config['trainer'], callbacks=callbacks, logger=logger)\n",
        "\n",
        "if trainer.logger:\n",
        "    trainer.logger.log_hyperparams(Namespace(**config))\n",
        "\n",
        "trainer.fit(lit_model, train_dataloaders=train_loader, val_dataloaders=test_loader)\n",
        "trainer.test(lit_model, dataloaders=test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "FtKkBzkBuoUx",
        "outputId": "9ba726b6-59ea-47c8-d249-de64f5f8c1e3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-5e2bc527b5b0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_lightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloggers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwandb\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWandbLogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mlit_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLitResNetTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lit_model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallback\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-40ad952a44d7>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, d_model, dim_feedforward, nhead, dropout, num_decoder_layers, max_output_len, lr, weight_decay, milestones, gamma)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{path}/latex_tokenizer.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         self.model = ResNetTransformer(\n\u001b[1;32m     32\u001b[0m             \u001b[0md_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer.from_file(f\"{path}/latex_tokenizer.json\")\n",
        "tokenizer."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkT5uomx06pU",
        "outputId": "ad27e1ec-303c-4cf9-f5d9-5e6669926eb0"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "157"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UA2-Mo2w1tWV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1yMRQK3G9aUwuxik-DWirWTNisHq_QcsN",
      "authorship_tag": "ABX9TyNFk/+NEQE2E21bq7ZglQd5",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}